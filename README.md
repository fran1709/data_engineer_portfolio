
Proyectos de Data Engineering con AWS, Airflow, Streamlit y más
En este repositorio encontrarás los detalles de los proyectos realizados como parte del curso de Data Engineering. A continuación, se presenta un resumen de los proyectos y las tecnologías aplicadas:

Proyecto 1: Automatización de Notificaciones Diarias
Tecnologías Utilizadas:
Python
Twilio para enviar notificaciones de texto a dispositivos móviles
Descripción:
Aprendizaje y aplicación de Twilio para enviar notificaciones diarias a dispositivos móviles utilizando Python. Se automatiza el envío de mensajes con información relevante o actualizaciones importantes.
Proyecto 2: Ingesta de Datos Web en Snowflake con Airflow
Tecnologías Utilizadas:
Python
Airflow para orquestación de tareas
Snowflake para almacenamiento de datos
Descripción:
Aprender y aplicar el uso de Airflow para crear pipelines de datos que extraen información de la web y la ingieren en una tabla de Snowflake. Se automatizan los procesos de extracción y carga de datos.
Proyecto 3: Extracción de Datos de YouTube con Python
Tecnologías Utilizadas:
Python
YouTube Data API
Descripción:
Aprendizaje y aplicación de la YouTube Data API para extraer datos de la plataforma de YouTube utilizando Python. Se obtiene información relevante de vídeos, canales o comentarios para su posterior análisis.
Proyecto 4: Creación de Aplicaciones Interactivas con Streamlit y Dockerización
Tecnologías Utilizadas:
Python
Streamlit para creación de aplicaciones interactivas
Docker para contenerización de aplicaciones
Descripción:
Aprender y aplicar Streamlit para crear aplicaciones interactivas que permiten visualizar y manipular datos de manera intuitiva. Además, se utiliza Docker para contenerizar estas aplicaciones y facilitar su despliegue en diferentes entornos.
Aprendizajes y Aplicaciones Adicionales
Consulta de datos con AWS Athena.
Uso de funciones Lambda para extraer datos de API's.
Automatización de procesos de extracción de datos usando Airflow.
Implementación de almacenamiento y orquestación en la nube mediante AWS Free Tier.
Desarrollo de habilidades en Python para procesamiento de datos.
¡Este repositorio te proporciona los recursos necesarios para convertirte en un Data Engineer experto en tecnologías de la nube, automatización y creación de aplicaciones interactivas!

User
en ingles
ChatGPT
Data Engineering Projects with AWS, Airflow, Streamlit, and More
In this repository, you'll find details of the projects completed as part of the Data Engineering course. Below is a summary of the projects and the technologies applied:

Project 1: Daily Notification Automation
Technologies Used:
Python
Twilio for sending text notifications to mobile devices
Description:
Learning and application of Twilio to send daily notifications to mobile devices using Python. Automating the sending of messages with relevant information or important updates.
Project 2: Web Data Ingestion into Snowflake with Airflow
Technologies Used:
Python
Airflow for task orchestration
Snowflake for data storage
Description:
Learning and application of Airflow to create data pipelines that extract information from the web and ingest it into a Snowflake table. Automating the processes of data extraction and loading.
Project 3: YouTube Data Extraction with Python
Technologies Used:
Python
YouTube Data API
Description:
Learning and application of the YouTube Data API to extract data from the YouTube platform using Python. Retrieving relevant information from videos, channels, or comments for further analysis.
Project 4: Creation of Interactive Applications with Streamlit and Dockerization
Technologies Used:
Python
Streamlit for creating interactive applications
Docker for containerizing applications
Description:
Learning and application of Streamlit to create interactive applications that allow for intuitive visualization and manipulation of data. Additionally, using Docker to containerize these applications for easy deployment in different environments.
Additional Learnings and Applications
Querying data with AWS Athena.
Using Lambda functions to extract data from APIs.
Automating data extraction processes using Airflow.
Implementing cloud storage and orchestration through AWS Free Tier.
Developing Python skills for data processing.
